{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wLvfIhdRWOo"
      },
      "source": [
        "# Day 9 Validating Model - Ad. Sale Prediction from Existing customer - Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iajVumj7Rs4h"
      },
      "source": [
        "### *Importing Libraries*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1-Wf0iPPs6T"
      },
      "source": [
        "import pandas as pd #useful for loading the dataset\n",
        "import numpy as np #to perform array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Lz-PKYMR7t8"
      },
      "source": [
        "### *Choose Dataset file from Local Directory*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6a0O9vBSArk"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBen_XVHSPRU"
      },
      "source": [
        "### *Load Dataset*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeZjE8bJSV_0"
      },
      "source": [
        "dataset = pd.read_csv('DigitalAd_dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KcGg4dqShgx"
      },
      "source": [
        "### *Summarize Dataset*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2Xq7IXnSkAe"
      },
      "source": [
        "print(dataset.shape)\n",
        "print(dataset.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOpwFI2SS5QW"
      },
      "source": [
        "### *Segregate Dataset into X(Input/IndependentVariable) & Y(Output/DependentVariable)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MHP8lXOTHuC"
      },
      "source": [
        "X = dataset.iloc[:, :-1].values\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQVReem0U0DU"
      },
      "source": [
        "Y = dataset.iloc[:, -1].values\n",
        "Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK0_6UrsVdrV"
      },
      "source": [
        "### *Splitting Dataset into Train & Test*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P48__zmyVigu"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em7vVHLvVxmn"
      },
      "source": [
        "### *Feature Scaling*\n",
        "### we scale our data to make all the features contribute equally to the result\n",
        "###Fit_Transform - fit method is calculating the mean and variance of each of the features present in our data\n",
        "###Transform - Transform method is transforming all the features using the respective mean and variance,\n",
        "###We want our test data to be a completely new and a surprise set for our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZY7r98iVz5J"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNsQel33WKOo"
      },
      "source": [
        "### *Training*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0feU7XXWMe5"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(random_state = 0)\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib7L9-PdYLFy"
      },
      "source": [
        "### *Prediction for all Test Data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U8YNYI4Wnkl"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M68QWVh45S4j"
      },
      "source": [
        "# **Evaluating Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DX08hVg9nuz"
      },
      "source": [
        "### *Confusion Matrix*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcsG6RJqacbw"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix: \")\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM9MHsX29rOz"
      },
      "source": [
        "### *Accuracy_Score*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsOqR_Qu9t_B"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy: {0}%\".format(accuracy_score(y_test, y_pred)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVocuKxd91a0"
      },
      "source": [
        "### *Receiver Operating Curve - ROC Curve*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwAhfcJo93YW"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nsProbability = [0 for _ in range(len(y_test))]\n",
        "lsProbability = model.predict_proba(X_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "lsProbability = lsProbability[:, 1]\n",
        "# calculate scores\n",
        "nsAUC = roc_auc_score(y_test, nsProbability)\n",
        "lrAUC = roc_auc_score(y_test, lsProbability)\n",
        "# summarize scores\n",
        "print('No Skill: ROC AUC=%.3f' % (nsAUC*100))\n",
        "print('Logistic Skill: ROC AUC=%.3f' % (lrAUC*100))\n",
        "# calculate roc curves\n",
        "nsFP, nsTP, _ = roc_curve(y_test, nsProbability)\n",
        "lrFP, lrTP, _ = roc_curve(y_test, lsProbability)\n",
        "# plot the roc curve for the model\n",
        "plt.plot(nsFP, nsTP, linestyle='--', label='No Skill')\n",
        "plt.plot(lrFP, lrTP, marker='*', label='Logistic')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5fSlZAsBR0l"
      },
      "source": [
        "### *Cross Validation Score*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWL6bFfkBUx_"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=10)\n",
        "result = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(\"CROSS VALIDATION SCORE: %.2f%%\" % (result.mean()*100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YopFtT6DDGKz"
      },
      "source": [
        "### *Stratifield K-fold Cross Validation*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "543E4HFKDLTw"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skfold = StratifiedKFold(n_splits=3)\n",
        "model_skfold = LogisticRegression()\n",
        "results_skfold = cross_val_score(model_skfold, X, Y, cv=skfold)\n",
        "print(\"STRATIFIELD K-FOLD SCORE: %.2f%%\" % (results_skfold.mean()*100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5mBbJkHP6CL"
      },
      "source": [
        "### *Cumulative Accuracy Profile (CAP) Curve*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8ZzLQ-6EFPQ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#Calculate Totals and Class Counts\n",
        "total = len(y_test)\n",
        "print(total)\n",
        "class_1_count = np.sum(y_test)\n",
        "print(class_1_count)\n",
        "class_0_count = total - class_1_count\n",
        "##Plot Random Model Line\n",
        "plt.plot([0, total], [0, class_1_count], c = 'r', linestyle = '--', label = 'Random Model')\n",
        "\n",
        "##Plot Perfect Model Line\n",
        "plt.plot([0, class_1_count, total],\n",
        "         [0, class_1_count, class_1_count],\n",
        "         c = 'grey',\n",
        "         linewidth = 2,\n",
        "         label = 'Perfect Model')\n",
        "##Compute and Plot the Model's CAP Curve\n",
        "probs = model.predict_proba(X_test)\n",
        "probs = probs[:, 1]\n",
        "model_y = [y for _, y in sorted(zip(probs, y_test), reverse = True)]\n",
        "y_values = np.append([0], np.cumsum(model_y))\n",
        "x_values = np.arange(0, total + 1)\n",
        "\n",
        "plt.plot(x_values,\n",
        "         y_values,\n",
        "         c = 'b',\n",
        "         label = 'LR Classifier',\n",
        "         linewidth = 4)\n",
        "\n",
        "index = int((50*total / 100))\n",
        "\n",
        "## 50% Verticcal line from x-axis\n",
        "plt.plot([index, index], [0, y_values[index]], c ='g', linestyle = '--')\n",
        "\n",
        "## Horizontal line to y-axis from prediction model\n",
        "plt.plot([0, index], [y_values[index], y_values[index]], c = 'g', linestyle = '--')\n",
        "\n",
        "class_1_observed = y_values[index] * 100 / max(y_values)\n",
        "plt.xlabel('Total observations')\n",
        "plt.ylabel('Class 1 observations')\n",
        "plt.title('Cumulative Accuracy Profile')\n",
        "plt.legend(loc = 'lower right')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}